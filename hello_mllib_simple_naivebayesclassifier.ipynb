{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello MLlib simple NaiveBayesClassifier  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prereqquisites\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Version:  3.4.1\n"
     ]
    }
   ],
   "source": [
    "# Spark Session and Context\n",
    "spark = SparkSession.builder.master(\"local\") \\\n",
    "        .appName(\"Simple_MLlib_NaiveBayesClassifier\") \\\n",
    "        .getOrCreate()\n",
    "print(\"Spark Version: \", spark.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+--------+--------+--------+\n",
      "| id|label|feature1|feature2|feature3|\n",
      "+---+-----+--------+--------+--------+\n",
      "|  0|    A|     1.0|     0.1|     0.3|\n",
      "|  1|    B|     0.5|     0.8|     0.7|\n",
      "|  2|    A|     0.8|     0.6|     0.4|\n",
      "|  3|    C|     0.2|     0.3|     0.9|\n",
      "|  4|    B|     0.9|     0.5|     0.6|\n",
      "|  5|    C|     0.3|     0.7|     0.2|\n",
      "+---+-----+--------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Make up some sample data\n",
    "data = [\n",
    "    (0, \"A\", 1.0, 0.1, 0.3),\n",
    "    (1, \"B\", 0.5, 0.8, 0.7),\n",
    "    (2, \"A\", 0.8, 0.6, 0.4),\n",
    "    (3, \"C\", 0.2, 0.3, 0.9),\n",
    "    (4, \"B\", 0.9, 0.5, 0.6),\n",
    "    (5, \"C\", 0.3, 0.7, 0.2)\n",
    "]\n",
    "columns = [\"id\", \"label\", \"feature1\", \"feature2\", \"feature3\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+--------+--------+--------+-------------+--------------+--------------------+--------------------+----------+\n",
      "| id|label|feature1|feature2|feature3|label_indexed|feature_vector|       rawPrediction|         probability|prediction|\n",
      "+---+-----+--------+--------+--------+-------------+--------------+--------------------+--------------------+----------+\n",
      "|  0|    A|     1.0|     0.1|     0.3|          2.0| [1.0,0.1,0.3]|[-2.4964710751612...|[0.37697596573430...|       0.0|\n",
      "|  1|    B|     0.5|     0.8|     0.7|          0.0| [0.5,0.8,0.7]|[-3.1855514980427...|[0.38327437818270...|       1.0|\n",
      "|  3|    C|     0.2|     0.3|     0.9|          1.0| [0.2,0.3,0.9]|[-2.5305187666962...|[0.37177717748222...|       1.0|\n",
      "|  4|    B|     0.9|     0.5|     0.6|          0.0| [0.9,0.5,0.6]|[-3.1685276522752...|[0.38358247423038...|       0.0|\n",
      "|  5|    C|     0.3|     0.7|     0.2|          1.0| [0.3,0.7,0.2]|[-2.3036626000303...|[0.38500113359949...|       1.0|\n",
      "+---+-----+--------+--------+--------+-------------+--------------+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "\n",
    "# Index the Labels\n",
    "# Convert string labels (\"A\", \"B\", \"C\") into numeric labels (0, 1, 2)\n",
    "string_indexer = StringIndexer(inputCol=\"label\", outputCol=\"label_indexed\")\n",
    "\n",
    "# Assemble Features\n",
    "vec_assembler = VectorAssembler(inputCols=[\"feature1\", \"feature2\", \"feature3\"], outputCol=\"feature_vector\")\n",
    "\n",
    "# Split data into Train and Test datasets\n",
    "df_train, df_test = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Define Naive Bayes Classifier\n",
    "nb_classifier = NaiveBayes(featuresCol=\"feature_vector\", labelCol=\"label_indexed\", modelType=\"multinomial\")\n",
    "\n",
    "# Build the Pipeline\n",
    "nb_pipeline = Pipeline(stages=[string_indexer, vec_assembler, nb_classifier])\n",
    "\n",
    "# Fit the Pipeline\n",
    "nb_pipeline_model = nb_pipeline.fit(df_train)\n",
    "\n",
    "# Make Predictions\n",
    "df_predictions = nb_pipeline_model.transform(df_train)\n",
    "\n",
    "df_predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6\n",
      "Precision: 0.4666666666666667\n",
      "Recall: 0.6000000000000001\n",
      "F1 Score: 0.52\n",
      "+---+--------------+-----+-------------+----------+--------------------+\n",
      "| id|feature_vector|label|label_indexed|prediction|         probability|\n",
      "+---+--------------+-----+-------------+----------+--------------------+\n",
      "|  0| [1.0,0.1,0.3]|    A|          2.0|       0.0|[0.37697596573430...|\n",
      "|  1| [0.5,0.8,0.7]|    B|          0.0|       1.0|[0.38327437818270...|\n",
      "|  3| [0.2,0.3,0.9]|    C|          1.0|       1.0|[0.37177717748222...|\n",
      "|  4| [0.9,0.5,0.6]|    B|          0.0|       0.0|[0.38358247423038...|\n",
      "|  5| [0.3,0.7,0.2]|    C|          1.0|       1.0|[0.38500113359949...|\n",
      "+---+--------------+-----+-------------+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Evaluate the Model\n",
    "# Evaluate accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label_indexed\", predictionCol=\"prediction\", metricName=\"accuracy\"\n",
    ")\n",
    "accuracy = evaluator.evaluate(df_predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Evaluate precision, recall, and F1-score\n",
    "precision_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label_indexed\", predictionCol=\"prediction\", metricName=\"weightedPrecision\"\n",
    ")\n",
    "precision = precision_evaluator.evaluate(df_predictions)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "recall_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label_indexed\", predictionCol=\"prediction\", metricName=\"weightedRecall\"\n",
    ")\n",
    "recall = recall_evaluator.evaluate(df_predictions)\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "f1_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label_indexed\", predictionCol=\"prediction\", metricName=\"f1\"\n",
    ")\n",
    "f1 = f1_evaluator.evaluate(df_predictions)\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# Inspect Predictions\n",
    "df_predictions.select(\"id\", \"feature_vector\", \"label\", \"label_indexed\", \"prediction\", \"probability\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
