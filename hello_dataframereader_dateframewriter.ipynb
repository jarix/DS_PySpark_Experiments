{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrameReader and DataFrameWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prerequisites\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import * \n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Version:  3.5.0\n"
     ]
    }
   ],
   "source": [
    "# Get SparkSession\n",
    "spark = SparkSession.builder.master(\"local\") \\\n",
    "    .appName(\"hello_dataframereads_dataframewriter\") \\\n",
    "    .getOrCreate() \n",
    "print(\"Spark Version: \", spark.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Parquet Data into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME               |ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------------------+-------------------+-----+\n",
      "|United States                   |Romania            |1    |\n",
      "|United States                   |Ireland            |264  |\n",
      "|United States                   |India              |69   |\n",
      "|Egypt                           |United States      |24   |\n",
      "|Equatorial Guinea               |United States      |1    |\n",
      "|United States                   |Singapore          |25   |\n",
      "|United States                   |Grenada            |54   |\n",
      "|Costa Rica                      |United States      |477  |\n",
      "|Senegal                         |United States      |29   |\n",
      "|United States                   |Marshall Islands   |44   |\n",
      "|Guyana                          |United States      |17   |\n",
      "|United States                   |Sint Maarten       |53   |\n",
      "|Malta                           |United States      |1    |\n",
      "|Bolivia                         |United States      |46   |\n",
      "|Anguilla                        |United States      |21   |\n",
      "|Turks and Caicos Islands        |United States      |136  |\n",
      "|United States                   |Afghanistan        |2    |\n",
      "|Saint Vincent and the Grenadines|United States      |1    |\n",
      "|Italy                           |United States      |390  |\n",
      "|United States                   |Russia             |156  |\n",
      "+--------------------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Total Number of records:  255\n"
     ]
    }
   ],
   "source": [
    "data_file_path = \"data/2010-summary.parquet\"\n",
    "df_parquet = spark.read.format(\"parquet\").load(data_file_path)\n",
    "df_parquet.show(truncate=False)\n",
    "print(\"Total Number of records: \", df_parquet.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DEST_COUNTRY_NAME: string (nullable = true)\n",
      " |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n",
      " |-- count: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_parquet.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Parquet Data into SQL Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME               |ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------------------+-------------------+-----+\n",
      "|United States                   |Romania            |1    |\n",
      "|United States                   |Ireland            |264  |\n",
      "|United States                   |India              |69   |\n",
      "|Egypt                           |United States      |24   |\n",
      "|Equatorial Guinea               |United States      |1    |\n",
      "|United States                   |Singapore          |25   |\n",
      "|United States                   |Grenada            |54   |\n",
      "|Costa Rica                      |United States      |477  |\n",
      "|Senegal                         |United States      |29   |\n",
      "|United States                   |Marshall Islands   |44   |\n",
      "|Guyana                          |United States      |17   |\n",
      "|United States                   |Sint Maarten       |53   |\n",
      "|Malta                           |United States      |1    |\n",
      "|Bolivia                         |United States      |46   |\n",
      "|Anguilla                        |United States      |21   |\n",
      "|Turks and Caicos Islands        |United States      |136  |\n",
      "|United States                   |Afghanistan        |2    |\n",
      "|Saint Vincent and the Grenadines|United States      |1    |\n",
      "|Italy                           |United States      |390  |\n",
      "|United States                   |Russia             |156  |\n",
      "+--------------------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"CREATE OR REPLACE TEMPORARY VIEW flights_table\n",
    "          USING parquet\n",
    "          OPTIONS (\n",
    "            path \"data/2010-summary.parquet/\")\n",
    "          \"\"\")\n",
    "\n",
    "spark.sql(\"SELECT * FROM flights_table\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to a SQL Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_parquet.write.mode(\"overwrite\").saveAsTable(\"international_flights_table\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read JSON Data into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME       |ORIGIN_COUNTRY_NAME|count|\n",
      "+------------------------+-------------------+-----+\n",
      "|United States           |Romania            |15   |\n",
      "|United States           |Croatia            |1    |\n",
      "|United States           |Ireland            |344  |\n",
      "|Egypt                   |United States      |15   |\n",
      "|United States           |India              |62   |\n",
      "|United States           |Singapore          |1    |\n",
      "|United States           |Grenada            |62   |\n",
      "|Costa Rica              |United States      |588  |\n",
      "|Senegal                 |United States      |40   |\n",
      "|Moldova                 |United States      |1    |\n",
      "|United States           |Sint Maarten       |325  |\n",
      "|United States           |Marshall Islands   |39   |\n",
      "|Guyana                  |United States      |64   |\n",
      "|Malta                   |United States      |1    |\n",
      "|Anguilla                |United States      |41   |\n",
      "|Bolivia                 |United States      |30   |\n",
      "|United States           |Paraguay           |6    |\n",
      "|Algeria                 |United States      |4    |\n",
      "|Turks and Caicos Islands|United States      |230  |\n",
      "|United States           |Gibraltar          |1    |\n",
      "+------------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Total NUmber of records:  1502\n"
     ]
    }
   ],
   "source": [
    "data_file_path = \"data/flights_json/*\"\n",
    "df_json = spark.read.format(\"json\").load(data_file_path)\n",
    "df_json.show(truncate=False)\n",
    "print(\"Total NUmber of records: \", df_json.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read JSON into SQL Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME       |ORIGIN_COUNTRY_NAME|count|\n",
      "+------------------------+-------------------+-----+\n",
      "|United States           |Romania            |15   |\n",
      "|United States           |Croatia            |1    |\n",
      "|United States           |Ireland            |344  |\n",
      "|Egypt                   |United States      |15   |\n",
      "|United States           |India              |62   |\n",
      "|United States           |Singapore          |1    |\n",
      "|United States           |Grenada            |62   |\n",
      "|Costa Rica              |United States      |588  |\n",
      "|Senegal                 |United States      |40   |\n",
      "|Moldova                 |United States      |1    |\n",
      "|United States           |Sint Maarten       |325  |\n",
      "|United States           |Marshall Islands   |39   |\n",
      "|Guyana                  |United States      |64   |\n",
      "|Malta                   |United States      |1    |\n",
      "|Anguilla                |United States      |41   |\n",
      "|Bolivia                 |United States      |30   |\n",
      "|United States           |Paraguay           |6    |\n",
      "|Algeria                 |United States      |4    |\n",
      "|Turks and Caicos Islands|United States      |230  |\n",
      "|United States           |Gibraltar          |1    |\n",
      "+------------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"CREATE OR REPLACE TEMPORARY VIEW flights_table_from_json\n",
    "          USING json\n",
    "          OPTIONS (\n",
    "            path \"data/flights_json/*\")\n",
    "          \"\"\")\n",
    "\n",
    "spark.sql(\"SELECT * FROM flights_table_from_json\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Dataframe into JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_json.write.format(\"json\")\n",
    "        .mode(\"overwrite\")\n",
    "        .save(\"data/international_flights_json\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CSV Data into Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+----------------+-----+\n",
      "|DEST_COUNTRY                    |ORIGIN_COUNTRY  |COUNT|\n",
      "+--------------------------------+----------------+-----+\n",
      "|United States                   |Romania         |1    |\n",
      "|United States                   |Ireland         |264  |\n",
      "|United States                   |India           |69   |\n",
      "|Egypt                           |United States   |24   |\n",
      "|Equatorial Guinea               |United States   |1    |\n",
      "|United States                   |Singapore       |25   |\n",
      "|United States                   |Grenada         |54   |\n",
      "|Costa Rica                      |United States   |477  |\n",
      "|Senegal                         |United States   |29   |\n",
      "|United States                   |Marshall Islands|44   |\n",
      "|Guyana                          |United States   |17   |\n",
      "|United States                   |Sint Maarten    |53   |\n",
      "|Malta                           |United States   |1    |\n",
      "|Bolivia                         |United States   |46   |\n",
      "|Anguilla                        |United States   |21   |\n",
      "|Turks and Caicos Islands        |United States   |136  |\n",
      "|United States                   |Afghanistan     |2    |\n",
      "|Saint Vincent and the Grenadines|United States   |1    |\n",
      "|Italy                           |United States   |390  |\n",
      "|United States                   |Russia          |156  |\n",
      "+--------------------------------+----------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Total NUmber of records:  1502\n"
     ]
    }
   ],
   "source": [
    "data_file_path = \"data/flights_csv/*\"\n",
    "\n",
    "schema = \"DEST_COUNTRY STRING, ORIGIN_COUNTRY STRING, COUNT INT\"\n",
    "\n",
    "df_csv = (spark.read.format(\"csv\") \n",
    "    .option(\"header\", \"true\")\n",
    "    .schema(schema)\n",
    "    .option(\"mode\", \"FAILFAST\")     # Exit if any errors\n",
    "    .option(\"nullValue\", \"\")        # Replace any null data field with quotes\n",
    "    .load(data_file_path)\n",
    ")\n",
    "\n",
    "df_csv.show(truncate=False)\n",
    "print(\"Total NUmber of records: \", df_csv.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CSV Data into SQL Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME               |ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------------------+-------------------+-----+\n",
      "|United States                   |Romania            |1    |\n",
      "|United States                   |Ireland            |264  |\n",
      "|United States                   |India              |69   |\n",
      "|Egypt                           |United States      |24   |\n",
      "|Equatorial Guinea               |United States      |1    |\n",
      "|United States                   |Singapore          |25   |\n",
      "|United States                   |Grenada            |54   |\n",
      "|Costa Rica                      |United States      |477  |\n",
      "|Senegal                         |United States      |29   |\n",
      "|United States                   |Marshall Islands   |44   |\n",
      "|Guyana                          |United States      |17   |\n",
      "|United States                   |Sint Maarten       |53   |\n",
      "|Malta                           |United States      |1    |\n",
      "|Bolivia                         |United States      |46   |\n",
      "|Anguilla                        |United States      |21   |\n",
      "|Turks and Caicos Islands        |United States      |136  |\n",
      "|United States                   |Afghanistan        |2    |\n",
      "|Saint Vincent and the Grenadines|United States      |1    |\n",
      "|Italy                           |United States      |390  |\n",
      "|United States                   |Russia             |156  |\n",
      "+--------------------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"CREATE OR REPLACE TEMPORARY VIEW flights_table_from_csv\n",
    "          USING csv\n",
    "          OPTIONS (\n",
    "            path \"data/flights_csv/*\", \n",
    "            header \"true\",\n",
    "            inferSchema \"true\",\n",
    "            mode \"FAILFAST\")\n",
    "          \"\"\")\n",
    "\n",
    "spark.sql(\"SELECT * FROM flights_table_from_csv\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Dataframe into CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_csv.write.format(\"csv\")\n",
    "        .mode(\"overwrite\")\n",
    "        .save(\"data/international_flights_csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
