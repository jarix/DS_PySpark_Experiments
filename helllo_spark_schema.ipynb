{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Schema Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prerequisites\n",
    "from pyspark.sql import SparkSession \n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Version:  3.5.0\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local\").getOrCreate()\n",
    "print(\"Spark Version: \", spark.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Schema Programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author: string (nullable = false)\n",
      " |-- title: string (nullable = false)\n",
      " |-- pages: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define Schema Programmatically\n",
    "schema_A = StructType([\n",
    "    StructField(\"author\", StringType(), False),\n",
    "    StructField(\"title\", StringType(), False),\n",
    "    StructField(\"pages\", IntegerType(), False)]\n",
    ")\n",
    "\n",
    "# Create static data\n",
    "data_A = [[\"George Orwell\", \"1984\", 352],\n",
    "          [\"Jane Austen\", \"Pride and Prejudice\", 456],\n",
    "          [\"Harper Lee\", \"To Kill a Mockingbird\", 399],\n",
    "          [\"Herman Melville\", \"Moby-Dick\", 511]\n",
    "]\n",
    "\n",
    "df_books_A = spark.createDataFrame(data_A, schema_A)\n",
    "df_books_A.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------------+-----+\n",
      "|author         |title                |pages|\n",
      "+---------------+---------------------+-----+\n",
      "|George Orwell  |1984                 |352  |\n",
      "|Jane Austen    |Pride and Prejudice  |456  |\n",
      "|Harper Lee     |To Kill a Mockingbird|399  |\n",
      "|Herman Melville|Moby-Dick            |511  |\n",
      "+---------------+---------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_books_A.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Schema with Data Description Language (DDL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- pages: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define Schema with DDL \n",
    "schema_B = \"author STRING, title STRING, pages INT\"\n",
    "\n",
    "data_B = [[\"George Orwell\", \"1984\", 352],\n",
    "          [\"Jane Austen\", \"Pride and Prejudice\", 456],\n",
    "          [\"Harper Lee\", \"To Kill a Mockingbird\", 399],\n",
    "          [\"Herman Melville\", \"Moby-Dick\", 511]\n",
    "]\n",
    "\n",
    "df_books_B = spark.createDataFrame(data_B, schema_B)\n",
    "df_books_B.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------------+-----+\n",
      "|author         |title                |pages|\n",
      "+---------------+---------------------+-----+\n",
      "|George Orwell  |1984                 |352  |\n",
      "|Jane Austen    |Pride and Prejudice  |456  |\n",
      "|Harper Lee     |To Kill a Mockingbird|399  |\n",
      "|Herman Melville|Moby-Dick            |511  |\n",
      "+---------------+---------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_books_B.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More complex Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- First: string (nullable = true)\n",
      " |-- Last: string (nullable = true)\n",
      " |-- Url: string (nullable = true)\n",
      " |-- Published: string (nullable = true)\n",
      " |-- Hits: integer (nullable = true)\n",
      " |-- Campaigns: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Yet another Schema\n",
    "schema_C = \"`Id` INT, `First` STRING, `Last` STRING, `Url` STRING, `Published` STRING, `Hits` INT, `Campaigns` ARRAY<STRING>\"\n",
    "\n",
    "data_C = [[1, \"Jules\", \"Damji\", \"https://tinyurl.1\", \"1/4/2016\", 4535, [\"twitter\", \"LinkedIn\"]],\n",
    "          [2, \"Brooke\",\"Wenig\", \"https://tinyurl.2\", \"5/5/2018\", 8908, [\"twitter\", \"LinkedIn\"]],\n",
    "          [3, \"Denny\", \"Lee\", \"https://tinyurl.3\", \"6/7/2019\", 7659, [\"web\",\"twitter\", \"FB\", \"LinkedIn\"]],\n",
    "          [4, \"Tathagata\", \"Das\", \"https://tinyurl.4\", \"5/12/2018\", 10568, [\"twitter\", \"FB\"]],\n",
    "          [5, \"Matei\",\"Zaharia\", \"https://tinyurl.5\", \"5/14/2014\", 40578, [\"web\", \"twitter\", \"FB\", \"LinkedIn\"]],\n",
    "          [6, \"Reynold\", \"Xin\", \"https://tinyurl.6\", \"3/2/2015\", 25568, [\"twitter\", \"LinkedIn\"]]\n",
    "      ]\n",
    "\n",
    "df_blogs = spark.createDataFrame(data_C, schema_C)\n",
    "df_blogs.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-------+-----------------+---------+-----+----------------------------+\n",
      "|Id |First    |Last   |Url              |Published|Hits |Campaigns                   |\n",
      "+---+---------+-------+-----------------+---------+-----+----------------------------+\n",
      "|1  |Jules    |Damji  |https://tinyurl.1|1/4/2016 |4535 |[twitter, LinkedIn]         |\n",
      "|2  |Brooke   |Wenig  |https://tinyurl.2|5/5/2018 |8908 |[twitter, LinkedIn]         |\n",
      "|3  |Denny    |Lee    |https://tinyurl.3|6/7/2019 |7659 |[web, twitter, FB, LinkedIn]|\n",
      "|4  |Tathagata|Das    |https://tinyurl.4|5/12/2018|10568|[twitter, FB]               |\n",
      "|5  |Matei    |Zaharia|https://tinyurl.5|5/14/2014|40578|[web, twitter, FB, LinkedIn]|\n",
      "|6  |Reynold  |Xin    |https://tinyurl.6|3/2/2015 |25568|[twitter, LinkedIn]         |\n",
      "+---+---------+-------+-----------------+---------+-----+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_blogs.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Schema from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- First: string (nullable = true)\n",
      " |-- Last: string (nullable = true)\n",
      " |-- Url: string (nullable = true)\n",
      " |-- Published: string (nullable = true)\n",
      " |-- Hits: integer (nullable = true)\n",
      " |-- Campaigns: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_blogs_2 = spark.read.schema(schema_C).json(\"data/blogs.json\")\n",
    "\n",
    "df_blogs_2.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-------+-----------------+---------+-----+----------------------------+\n",
      "|Id |First    |Last   |Url              |Published|Hits |Campaigns                   |\n",
      "+---+---------+-------+-----------------+---------+-----+----------------------------+\n",
      "|1  |Jules    |Damji  |https://tinyurl.1|1/4/2016 |4535 |[twitter, LinkedIn]         |\n",
      "|2  |Brooke   |Wenig  |https://tinyurl.2|5/5/2018 |8908 |[twitter, LinkedIn]         |\n",
      "|3  |Denny    |Lee    |https://tinyurl.3|6/7/2019 |7659 |[web, twitter, FB, LinkedIn]|\n",
      "|4  |Tathagata|Das    |https://tinyurl.4|5/12/2018|10568|[twitter, FB]               |\n",
      "|5  |Matei    |Zaharia|https://tinyurl.5|5/14/2014|40578|[web, twitter, FB, LinkedIn]|\n",
      "|6  |Reynold  |Xin    |https://tinyurl.6|3/2/2015 |25568|[twitter, LinkedIn]         |\n",
      "+---+---------+-------+-----------------+---------+-----+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_blogs_2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
